{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FO-731_Pre-train_JSN-prediction_classifier_1\n",
    "Training JSN-prediction classifier using pre-trained ResNet Autoencoder<br>\n",
    "\n",
    "\n",
    "author = MV<br>\n",
    "date = 2021-10-11<br>\n",
    "\n",
    "_______________________________________\n",
    "\n",
    "Training with image data and all numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this defines the GPU you are using\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for dnn2 and labelbox-connector\n",
    "import sys\n",
    "sys.path.insert(1, \"/srv/dnn-framework\")\n",
    "sys.path.insert(1, \"/srv/labelbox-connector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "#dnn\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "#framework\n",
    "from framework.utils.app_base import DnnApp\n",
    "from framework.utils import Landmarks, BoundingBox, img_utils\n",
    "from framework.loader import LmBlobBatchGenerator\n",
    "from framework.dataset import DatasetAugmented\n",
    "from framework.preprocessing import preprocessing, image_processing\n",
    "from framework.augmentor import AugmentorImage\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, cohen_kappa_score, roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import itertools\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "\n",
    "from network.iblmodel import IBLModel as Model\n",
    "from network.RetinaNet.resnet import ResNet2D50\n",
    "from keras.layers import Input, Dense, LeakyReLU, Dropout, Concatenate"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# labelbox-connector\n",
    "from LabelBox.LB_project import LBProject\n",
    "from LabelBox.LB_extractor import LBExtractor\n",
    "from LabelBox.LB_parser import LBParser\n",
    "\n",
    "from LabelBox.LB_talker import LBTalker\n",
    "from LabelBox.S3_talker import S3Talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asc' 'time)s %(name)-25s %(level' 'name)-8s %(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO) # you change this to logging.DEBUG to get more logging information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session config - if needed\n",
    "import tensorflow.keras.backend as K\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "## Load Yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "yaml_path= '/srv/Class_def_files/FO-731_Pre-training_JSN20%_Numeric.yaml'\n",
    "app = DnnApp(yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Batchgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSNClassBatchGenerator(LmBlobBatchGenerator):\n",
    "    \"\"\"Batch Generator for Classifing JSN into slow and fast progressors\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dataset=None,\n",
    "                 batch_size=None,\n",
    "                 in_columns=None,\n",
    "                 out_columns=None,\n",
    "                 shuffle=False):\n",
    "        \"\"\"\n",
    "        Override of init\n",
    "        \"\"\"\n",
    "        super().__init__(dataset, batch_size, {\"img_path_pro\":\"img_path_pro\"},{\"img_path_pro\":\"img_path_pro\"}, shuffle)\n",
    "        self.classf_name = \"class\"\n",
    "        self.file_name = \"img_path_pro\"\n",
    "        self.numeric_names = [\n",
    "            'Patient Sex_S',\n",
    "            'BMI_S',\n",
    "            'Patient Age_S',\n",
    "            'Hip_symptoms_S',\n",
    "            'WOMAC_dis_S',\n",
    "            'WOMAC_pain_S',\n",
    "            'WOMAC_stiff_S',\n",
    "            'other_knee_KOA_S',\n",
    "            'KL-grade_a_S']\n",
    "        self.output_channels_classf = 2\n",
    "        \n",
    "        # augmentation\n",
    "        self.rotate = None # rotate the img l/r with max this angle\n",
    "        self.p_augment = 0.0 # probability with which to augment      \n",
    "        self.augmentation = False\n",
    "        \n",
    "        # preprocessing\n",
    "        self.my_size = [512, 1024]\n",
    "        self.current_batch_size = 4\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=2., tileGridSize=(3,7)) # 2, (16,16)\n",
    "        \n",
    "    @staticmethod\n",
    "    def gaussian(x, mu, sig):\n",
    "            return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))    \n",
    "        \n",
    "    def do_augment(self, image, out_size):        \n",
    "        # image augment            \n",
    "        if np.random.uniform() < self.p_augment:    \n",
    "            aug = A.Compose([A.RandomBrightness(p=0.5),\n",
    "                       A.RandomGamma(p=0.5),\n",
    "                       A.RandomContrast(limit=0.7,p=0.5),  \n",
    "                       A.ShiftScaleRotate(shift_limit=0.0325, scale_limit=0.15, rotate_limit=0, interpolation=1, border_mode=cv2.BORDER_CONSTANT, always_apply=False, p=0.5),\n",
    "                       A.GaussNoise(p=0.3),\n",
    "                       A.Rotate(limit=self.rotate, interpolation=1, border_mode=cv2.BORDER_CONSTANT, always_apply=False, p=0.5),\n",
    "                       A.GridDistortion(num_steps=3, distort_limit=0.05, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "                      ]) \n",
    "                                       \n",
    "            augmented = aug(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image\n",
    "    \n",
    "    def next_internal(self):\n",
    "        \"\"\"\n",
    "        Internal function of the next operator. The output is NOT formatted so\n",
    "        that it can be used to train keras models in a tuple, it is a stack of\n",
    "        images/landmarks. Formatting needs to happen in the operator call.\n",
    "\n",
    "        :return: stack of images, stack of labels\n",
    "        \"\"\"\n",
    "        indices = self._get_next_chunk()\n",
    "        \n",
    "        data_frame = pd.DataFrame(index=indices, columns=[self.file_name, self.classf_name] + self.numeric_names)\n",
    "        \n",
    "        logging.debug(\"JSNClassBatchGenerator: next internal dataset_name: %s\" % self.dataset.dataset_name)\n",
    "        out_size = tuple(self.my_size)\n",
    "        \n",
    "        for idx in indices:\n",
    "            try:\n",
    "                row = self.dataset[idx]\n",
    "                image = row[self.file_name]\n",
    "                res_image = None\n",
    "                res_image = cv2.normalize(image, res_image, 0, 255, cv2.NORM_MINMAX, cv2.CV_32FC1)            \n",
    "                row[self.file_name] = res_image\n",
    "                row[self.classf_name] = row[self.classf_name]                \n",
    "                \n",
    "                #print({k:v for k,v in row.items() if k in self.numeric_names})        \n",
    "                data_frame.loc[idx] = row\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.exception(\"ResNetClassBatchGenerator: Row idx {0}: {1}\".format(idx, e))     \n",
    "        \n",
    "        self.current_batch_size = data_frame.shape[0]\n",
    "        \n",
    "        inputs = np.stack(data_frame[self.file_name]).astype(np.float32)\n",
    "        outputs = np.stack(data_frame[self.classf_name]).astype(np.float32)\n",
    "        \n",
    "        inputs = {\"input_2\": inputs.reshape(self.input_shape)}#, \"numeric\": inputs.reshape(self.input_shape)}\n",
    "        inputs[\"numeric\"] = np.stack(np.array(data_frame[self.numeric_names]))#.astype(np.float32)\n",
    "        \n",
    "        return inputs, outputs\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def out_shape(self):\n",
    "        return self.current_batch_size, 1\n",
    "    \n",
    "    @property\n",
    "    def input_shape(self):\n",
    "        return self.current_batch_size, self.my_size[1], self.my_size[0], self.input_channels\n",
    "    \n",
    "    def __next__(self):\n",
    "        \"\"\"\n",
    "        Call of the batch generator by keras, Override\n",
    "\n",
    "        :returns input images, output blobs\n",
    "        \"\"\"\n",
    "        inputs, outputs = self.next_internal()\n",
    "        \n",
    "        return inputs, outputs.reshape(self.out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the BG TTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DatasetAugmented('train', app.datasets['data_train'].all, None)\n",
    "tune = DatasetAugmented('tune', app.datasets['data_tune'].all, None)\n",
    "test = DatasetAugmented('test', app.datasets['data_test'].all, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "bg_train = JSNClassBatchGenerator(train, batch_size=batch_sz, shuffle=True)\n",
    "bg_tune = JSNClassBatchGenerator(tune, batch_size=batch_sz, shuffle=True)\n",
    "bg_test = JSNClassBatchGenerator(test, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_train.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bg_train.rotate = 15\n",
    "#bg_train.p_augment = 0.5  \n",
    "bg_train.augmentation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.RetinaNet.resnet_classifier import ResNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ResNet50 Classifier Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weights_resnet50 = \"/srv/dnn-framework/FO-719_RetinaNet_pretrain/res_net_Clf_run_Sep-21-2021.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_clf = ResNetClassifier(num_classes = [2,7], in_size = (1024,512,1)).create()\n",
    "ResNet_clf.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ResNet_clf.load_weights(path_weights_resnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove and add new layers to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 9 # len numeric\n",
    "inputs_2 = Input(shape=(m,), name=\"numeric\")\n",
    "dense = Dense(32 * m, activation=\"relu\")(inputs_2)\n",
    "dropout = Dropout(0.3)(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JSN_clf = ResNetClassifier(num_classes=[1], in_size = (1024,512,1)).create(head='default')\n",
    "JSN_clf.layers.pop()\n",
    "n=2048\n",
    "inputs = JSN_clf.input\n",
    "\n",
    "#x = keras.layers.Dropout(0.5, name=\"Dropout_0.5\")(JSN_clf.layers[-1].output)\n",
    "x = keras.layers.Dense(n, activation=None)(JSN_clf.layers[-1].output)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Concatenate()([dropout, x])\n",
    "\n",
    "x = keras.layers.Dense(n//2, activation=None)(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = keras.layers.Dense(1, activation='sigmoid',name=\"jsn\")(x)\n",
    "\n",
    "JSN_clf = Model([inputs, inputs_2], x)\n",
    "JSN_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSN_clf.inputs, JSN_clf.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_n_dirty = {\"input_2\":np.random.uniform(size=(1,1024,512,1)), 'numeric':np.random.uniform(size=(1,m))}\n",
    "JSN_clf.predict(fast_n_dirty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (layer_resnet, layer_jsn) in enumerate(zip(ResNet_clf.layers, JSN_clf.layers)):\n",
    "    print(i, end='\\r')\n",
    "    if i>188:\n",
    "        break\n",
    "    layer_jsn.set_weights(layer_resnet.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing layers\n",
    "Do not allow already good layers to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(JSN_clf.layers):\n",
    "    print(f\"{i}:{layer.name}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, layer_jsn in enumerate(JSN_clf.layers):\n",
    "    if i<=188:\n",
    "        layer_jsn.set_trainable = False\n",
    "    else:\n",
    "        layer_jsn.set_trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "## Define the training Schedule"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path_tensorboard = \"/srv/dnn-framework/logs/tensorboard/\"\n",
    "if not os.path.isdir(path_tensorboard):\n",
    "    os.mkdir(path_tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "path_tensorboard = \"/srv/dnn-framework/logs/tensorboard/\"\n",
    "\n",
    "#old_weights = './JSN_clf_run_Dec-15-2021_0_Inge_NoAug.hdf5'\n",
    "#JSN_clf.load_weights(old_weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "old_weights = './JSN_clf_run_Dec-09-2021_153_Gerdi_NoAug.hdf5'\n",
    "JSN_clf.load_weights(old_weights)\n",
    "\n",
    "# Freeze whole base model\n",
    "f_num = 153\n",
    "for i, layer_jsn in enumerate(JSN_clf.layers):\n",
    "    if (i<=f_num) | ('BatchNormalization' in str(layer_jsn)):\n",
    "        layer_jsn.set_trainable = False\n",
    "    else:\n",
    "        layer_jsn.set_trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First run\n",
    "f_num = 0\n",
    "# define tag\n",
    "tag = 'JSN_clf_run_{0}_{1}_Jan_NoAug'.format(today.strftime(\"%b-%d-%Y\"),f_num)\n",
    "print(tag)\n",
    "\n",
    "#callbacks and optimizer\n",
    "bg_train.batch_size = 8\n",
    "reduce_call_back = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=5,\n",
    "                                         verbose=1,\n",
    "                                         mode='min',\n",
    "                                         cooldown=2,\n",
    "                                         min_lr=1e-012)\n",
    "\n",
    "model_chkpnt_call_back = ModelCheckpoint(tag+\".hdf5\",\n",
    "                                         monitor='val_loss',\n",
    "                                         verbose=1,\n",
    "                                         save_best_only=True)\n",
    "\n",
    "tb_call_back = TensorBoard(log_dir=os.path.join(path_tensorboard, tag),\n",
    "                           histogram_freq=0,\n",
    "                           write_graph=True,\n",
    "                           write_images=True,\n",
    "                           write_grads=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=12,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [#reduce_call_back,\n",
    "             model_chkpnt_call_back,\n",
    "             tb_call_back,\n",
    "             #early_stopping\n",
    "            ]\n",
    "\n",
    "bg_train.batch_size = 4\n",
    "bg_tune.batch_size = 4\n",
    "bg_train.augmentation = False\n",
    "bg_train.current_batch_size\n",
    "\n",
    "opt = Adam(lr=1e-05)\n",
    "JSN_clf.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "              metrics={'jsn': tf.keras.metrics.AUC()})\n",
    "\n",
    "# Train\n",
    "JSN_clf.fit_generator(bg_train, len(bg_train),  # Nitems in train set\n",
    "                    300,  # total epochs\n",
    "                    verbose=1,\n",
    "                    # validation set gen (img, labels)\n",
    "                    validation_data=bg_tune,\n",
    "                    # Nitems in validation set\n",
    "                    validation_steps=len(bg_tune),\n",
    "                    callbacks=callbacks,\n",
    "                    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from framework.validation.validation_classification import ClassificationValidator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tag = './JSN_clf_run_Nov-25-2021_188_Ferdi_NoAug.hdf5'\n",
    "JSN_clf.load_weights(old_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JSN_clf_val_bg = ClassificationValidator(JSN_clf)\n",
    "JSN_clf_val_bg.evaluate(bg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = np.array([0])\n",
    "pred_y = np.array([0])\n",
    "for _ in range(len(bg_test)):\n",
    "    i, c = next(bg_test)\n",
    "    true_y = np.vstack((true_y,c))\n",
    "    pred_y = np.vstack((pred_y,JSN_clf.predict(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics  import  confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(true_y, pred_y>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, t = roc_curve(true_y, pred_y)\n",
    "auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim((0,1))\n",
    "plt.xlim((0,1))\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "#plt.plot(fpr,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAI.csv')\n",
    "df[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_test.dataset.data['class'].apply(lambda x: x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSN_clf_val_bg.print_error_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSN_clf_val_bg.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSN_clf_val_bg.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, classes, fs=(6, 6)):\n",
    "        plt.rcParams.update({'font.size': 16})\n",
    "        plt.figure(figsize=fs)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens, resample=False)\n",
    "\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.yticks(tick_marks, classes)\n",
    "        plt.xticks(tick_marks, classes)\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, np.round(cm[i, j] * 100, 1),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > 1.5 * thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "        \n",
    "def make_binary(arr, thresh=0.5):\n",
    "    return (np.asarray(arr) > thresh).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_use = bg_test\n",
    "#bg_use.batch_size = 248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "for i in range(len(bg_use)):\n",
    "    imgs, labs = next(bg_use)\n",
    "    lab=labs['jsn']\n",
    "    \n",
    "    pred = JSN_clf.predict(imgs)\n",
    "    \n",
    "    all_labels += np.argmax(lab, axis=1).flatten().tolist()\n",
    "    all_preds += np.argmax(pred, axis=1).flatten().tolist()\n",
    "    \n",
    "    print(f\"Mini Batch {i+1}/{len(bg_use)}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
