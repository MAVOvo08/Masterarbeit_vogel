{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masterfiles for JSN prediction\n",
    "Create MAsterfiles with different class definitions and exclusion criteria <br>\n",
    "Split Training in OAI, MOST und CHECK\n",
    "\n",
    "\n",
    "author = MV<br>\n",
    "date = 2021-11-12<br>\n",
    "\n",
    "_______________________________________\n",
    "\n",
    "## CSV files\n",
    "All Masterfiles contain data from OAI, MOST and CHECK\n",
    "\n",
    "- Master_20JSN_XML_ex4.csv (/srv/Class_def_files/Master_20JSN_XML_ex4.csv)\n",
    "    - class definition: 20% JSN/ 2 years\n",
    "    - exclusion: KL 4 at baseline\n",
    "    - numeric data: not normalized\n",
    "    - mis sing values: included<br><br>\n",
    "\n",
    "- Master_20JSN_XML_ex014.csv (/srv/Class_def_files/Master_20JSN_XML_ex014.csv)\n",
    "    - class definition: 20% JSN/ 2 years\n",
    "    - exclusion: KL 0-0, KL1-1, KL 4 at baseline\n",
    "    - numeric data: not normalized and standardized\n",
    "    - missing values: included<br><br>\n",
    "    \n",
    "- Master_10JSN_XML_ex014.csv (/srv/Master_10JSN_XML_ex014.csv)\n",
    "    - class definition: 10% JSN/ 2 years\n",
    "    - exclusion: KL 0-0, KL1-1, KL 4 at baseline\n",
    "    - numeric data: not normalized and standardized\n",
    "    - missing values: included<br><br>\n",
    "    \n",
    "- Nonan_Master_20JSN_XML_ex014_2.csv (/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv)\n",
    "    - class definition: 20% JSN/2 years\n",
    "    - exclusion: KL 0-0, KL1-1, KL 4 at baseline\n",
    "    - missing values: excluded<br><br>\n",
    "    \n",
    "- Master_10JSN.csv (/srv/Master_10JSN.csv)\n",
    "    - class definition: 10% JSN/ 2 years\n",
    "    - exclusion: KL 0-0, KL1-1, KL 4 at baseline\n",
    "    - numeric data: not normalized and standardized\n",
    "    - missing values: excluded<br><br>\n",
    "\n",
    "## Information in csv files\n",
    "\n",
    "Content: Patient ID,VISIT,Laterality,ID,Study,Patient Sex, Patient Age, BMI, Knee_inj (arthritis mediaction injection, 0:no, 1:yes), Hip_symptoms (0:no, 1: yes), WOMAC_dis (disability), WOMAC_pain, WOMAC_stiff (stiffness), KL , Implant (0:no, 1: yes), osteophytes (OARSI from KOALA), KL-grade (from KOALA), sclerosis (OARSI from KOALA), other_knee_KOA (contralateral KOA, 0:no, 1: yes), class\n",
    "\n",
    "Columns ending with \"_S\" are standardized \n",
    "\n",
    "- KL-grade_a,KL-grade_b,sclerosis_a,sclerosis_b,osteophytes_a,osteophytes_b: information of KOALA (a:year0, b:year1 or 2)\n",
    "\n",
    "- img_path/dicom_img_path: dicom image path\n",
    "- img_path_cut: ROI of image\n",
    "- img_path_pro: cutted image with preprocessing (resized, normalized, Gaussian blur, Clahe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this defines the GPU you are using\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for dnn2 and labelbox-connector\n",
    "import sys\n",
    "sys.path.insert(1, \"/srv/dnn-framework2\")\n",
    "sys.path.insert(1, \"/srv/labelbox-connector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn2 framework\n",
    "from framework.dnn_app.dnn_app import DnnApp\n",
    "from framework.data_objects import *\n",
    "from framework.dataset.dataset_collection import DatasetCollection\n",
    "from framework.dataset.csv_data_helper import CsvDataHelper\n",
    "from framework.batch_generator.batch_generator import BatchGenerator\n",
    "from framework.models.model_generator import ModelGenerator\n",
    "from framework.trainings_scheduler.trainings_scheduler import TrainingsScheduler\n",
    "\n",
    "# dnn2 networks\n",
    "from networks.models.ModelTypes import ModelTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelbox-connector\n",
    "from LabelBox.LB_project import LBProject\n",
    "from LabelBox.LB_extractor import LBExtractor\n",
    "from LabelBox.LB_parser import LBParser\n",
    "\n",
    "from LabelBox.LB_talker import LBTalker\n",
    "from LabelBox.S3_talker import S3Talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asc' 'time)s %(name)-25s %(level' 'name)-8s %(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO) # you change this to logging.DEBUG to get more logging information"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#session config - if needed\n",
    "import tensorflow.keras.backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masterfile 20% JSN and exclusion of KL4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/JSN_all_XML.csv')\n",
    "df1 = df.drop(columns={'Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','Unnamed: 0.1.1.1','coords_bbox_a','rotation_a','rotation_b','coords_bbox_b'})\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.dropna(subset=['class_MED','class_LAT'], how = 'all')\n",
    "\n",
    "# exclusion of KL 4 at baseline\n",
    "df3 = df2[df2['KL-grade_a'] != 4]\n",
    "\n",
    "df3['KL-grade_a'] = df3['KL-grade_a'].replace([-1.5],np.nan)\n",
    "df3['KL-grade_b'] = df3['KL-grade_b'].replace([-1.5],np.nan)\n",
    "\n",
    "# add one general class combining class_MED and class_LAT\n",
    "df3['class']=''\n",
    "for i, row in df3.iterrows():\n",
    "    if (df3['class_MED'][i]==1) | (df['class_LAT'][i]==1):\n",
    "        df3['class'][i]=1\n",
    "    else:\n",
    "        df3['class'][i]=0\n",
    "\n",
    "print('Class 0:',len(df3.loc[df3['class'] == 0]))\n",
    "print('Class 1:',len(df3.loc[df3['class'] == 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class to master csv\n",
    "df_master = pd.read_csv('/srv/Master_dataset_JSN.csv')\n",
    "\n",
    "df4 = df3.rename(columns = {'ID_a':'ID'})\n",
    "df5 = df_master.merge(df4[['ID','Laterality','class_MED','class_LAT','sclerosis_a', 'KL-grade_a', 'osteophytes_a', 'sclerosis_b','KL-grade_b', 'osteophytes_b','class']], on = ['ID','Laterality'], how = 'right')\n",
    "df5.to_csv('/srv/Class_def_files/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminate bad segm (-> e)\n",
    "\n",
    "df5 = pd.read_csv('/srv/Class_def_files/temp.csv')\n",
    "a = pd.read_csv('/srv/Class_def_files/FailedKOALAxml.csv')\n",
    "\n",
    "a = a.replace(['l','r'], ['L','R']).rename(columns={'Side': 'Laterality'})\n",
    "m = a.merge(df5, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    index = m['Unnamed: 0'][i]\n",
    "    indices.append(index)\n",
    "    \n",
    "d = df5.drop(indices, axis = 0).reset_index()\n",
    "e = d.drop(columns=['index'])\n",
    "    \n",
    "## Eliminate implants from dataframe (438 images)(-> df_f)\n",
    "\n",
    "imp_df = pd.read_csv('/srv/Implants.csv')\n",
    "\n",
    "imp_df = imp_df.replace(['l','r'], ['L','R'])\n",
    "m = imp_df.merge(e, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    idx = m['Unnamed: 0'][i]\n",
    "    indices.append(idx)\n",
    "    \n",
    "df_f = e.drop(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column for contralateral KOA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_f.sort_values(by = 'ID')\n",
    "mask = df_f.duplicated(subset=['ID'], keep = False)\n",
    "\n",
    "# keep only bilateral images \n",
    "df_d = df_f[mask].reset_index()\n",
    "\n",
    "df_d['other_knee_KOA']=''\n",
    "\n",
    "# add other knee fast progressor column\n",
    "for idx, row in df_d.iterrows():\n",
    "\n",
    "    print(idx, end = '\\r')\n",
    "    i = idx+1 # idx = first row, i = following row \n",
    "\n",
    "    if df_d['ID'][i] == df_d['ID'][idx]:\n",
    "        if df_d['KL-grade_a'][idx]>=3:\n",
    "            df_d['other_knee_KOA'][i]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][i]= 0\n",
    "            \n",
    "        if df_d['KL-grade_a'][i]>=3:\n",
    "            df_d['other_knee_KOA'][idx]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][idx]= 0\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_f.merge(df_d[['ID','Laterality','other_knee_KOA']], on = ['ID', 'Laterality'], how = 'left')\n",
    "\n",
    "df_new = df_new.rename(columns = {'img_path':'dicom_img_path'})\n",
    "\n",
    "df_new = df_new.replace({'Patient Sex': {'M': 0}})\n",
    "df_new = df_new.replace({'Patient Sex': {'F': 1}})\n",
    "df_new = df_new.replace({'Hip_symptoms': {'No':0, 'Yes':1, '1: Yes': 1, '.: Missing Form/Incomplete Workbook':np.nan, '8':np.nan, 'P':np.nan}})\n",
    "df_new = df_new.replace({'Knee_inj': {'1: Yes': 1,'.: Missing Form/Incomplete Workbook':np.nan}})\n",
    "\n",
    "df_new = df_new.replace({'WOMAC_dis': {'M': np.nan}})\n",
    "df_new = df_new.replace({'WOMAC_stiff': {'M': np.nan}})\n",
    "df_new = df_new.replace({'WOMAC_pain': {'M': np.nan}})\n",
    "\n",
    "df_new['WOMAC_dis'] = df_new['WOMAC_dis'].astype('float')\n",
    "df_new['WOMAC_stiff'] = df_new['WOMAC_stiff'].astype('float')\n",
    "df_new['WOMAC_pain'] = df_new['WOMAC_pain'].astype('float')\n",
    "df_new['Hip_symptoms'] = df_new['Hip_symptoms'].astype('float')\n",
    "df_new['Knee_inj'] = df_new['Knee_inj'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new.copy()\n",
    "\n",
    "# Add cut_img path to dataframe\n",
    "df['img_path_cut']=''\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    l = df.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df['img_path_cut'][i] = fn\n",
    "\n",
    "# Add preprocessed path to dataframe \n",
    "df['img_path_pro']=''\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    l = df.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees/Clahe-pngs', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df['img_path_pro'][i] = fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop images with 'no shape'\n",
    "#df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')\n",
    "df = df.drop([10036, 12185, 12187, 12189, 15427, 19522, 29032, 34220, 35483, 35945])\n",
    "df = df.drop(columns={'KL','Implant','Knee_inj'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna()\n",
    "df1.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop NaN values \n",
    "df = df.dropna()\n",
    "df.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_train.csv')\n",
    "df.Knee_inj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfst = pd.read_csv('Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex4.csv')\n",
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_test.csv')\n",
    "dfst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.merge(dfst, on=['ID','Laterality'], how='left')\n",
    "df_new = df_new[['Patient ID', 'VISIT',\n",
    "       'Laterality', 'ID', 'Study', 'dicom_img_path', 'Patient Sex',\n",
    "       'Patient Age', 'BMI', 'Hip_symptoms', 'WOMAC_dis',\n",
    "       'WOMAC_pain', 'WOMAC_stiff', 'sclerosis_a',\n",
    "       'KL-grade_a', 'osteophytes_a', 'class_x', 'other_knee_KOA', 'img_path_cut',\n",
    "       'img_path_pro', 'Patient Sex_S', 'Patient Age_S',\n",
    "       'BMI_S', 'Hip_symptoms_S', 'WOMAC_dis_S', 'WOMAC_stiff_S',\n",
    "       'WOMAC_pain_S', 'other_knee_KOA_S', 'KL-grade_a_S', 'sclerosis_a_S',\n",
    "       'osteophytes_a_S']]\n",
    "df_new = df_new.rename(columns={'class_x':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training, Test, Tune set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new.copy()\n",
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "dfTrain.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_train_2.csv')\n",
    "dfTest.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_test_2.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex4_tune_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.dropna()\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masterfile 20% JSN and exclusion of KL0-0, KL1-1, KL4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/JSN_all_XML.csv')\n",
    "df_x = df.dropna(subset=['class_MED','class_LAT'], how = 'all')\n",
    "print(len(df_x))\n",
    "\n",
    "# exclude if KL stays 0\n",
    "df_y = df_x.drop(df_x[(df_x['KL-grade_a'] ==0) & (df_x['KL-grade_b'] ==0)].index)\n",
    "print(len(df_y))\n",
    "\n",
    "# exclude if KL stays 1\n",
    "df_z = df_y.drop(df_y[(df_y['KL-grade_a'] ==1) & (df_y['KL-grade_b'] ==1)].index)\n",
    "print(len(df_z))\n",
    "\n",
    "# exclude if KL_a is 4 at baseline\n",
    "df8 = df_z[df_z['KL-grade_a'] != 4]\n",
    "\n",
    "df8['KL-grade_a'] = df8['KL-grade_a'].replace([-1],np.nan)\n",
    "df8['KL-grade_b'] = df8['KL-grade_b'].replace([-1],np.nan)\n",
    "\n",
    "# add one general class combining class_MED and class_LAT\n",
    "df8['class']=''\n",
    "for i, row in df8.iterrows():\n",
    "    if (df8['class_MED'][i]==1) | (df['class_LAT'][i]==1):\n",
    "        df8['class'][i]=1\n",
    "    else:\n",
    "        df8['class'][i]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df8.drop(columns={'Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','Unnamed: 0.1.1.1'})\n",
    "#df9.to_csv('/srv/Class_def_files/JSN_all_XML_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class to master csv\n",
    "df_master = pd.read_csv('/srv/Master_dataset_JSN.csv')\n",
    "\n",
    "df7_tmp = df9.rename(columns = {'ID_a':'ID'})\n",
    "df_c = df_master.merge(df7_tmp[['ID','Laterality','KL-grade_a','KL-grade_b','sclerosis_a','sclerosis_b','osteophytes_a','osteophytes_b','class']], on = ['ID','Laterality'], how = 'right')\n",
    "df_c = df_c.drop(columns={'Implant','KL','Knee_inj'})\n",
    "df_c.to_csv('/srv/Class_def_files/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminate bad segm (-> e)\n",
    "\n",
    "df_c = pd.read_csv('/srv/Class_def_files/temp.csv')\n",
    "a = pd.read_csv('/srv/Class_def_files/FailedKOALAxml.csv')\n",
    "\n",
    "a = a.replace(['l','r'], ['L','R']).rename(columns={'Side': 'Laterality'})\n",
    "m = a.merge(df_c, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    index = m['Unnamed: 0'][i]\n",
    "    indices.append(index)\n",
    "    \n",
    "d = df_c.drop(indices, axis = 0).reset_index()\n",
    "e = d.drop(columns=['index'])\n",
    "    \n",
    "    \n",
    "## Eliminate from dataframe (438 images)(-> df_f)\n",
    "\n",
    "imp_df = pd.read_csv('/srv/Implants.csv')\n",
    "\n",
    "imp_df = imp_df.replace(['l','r'], ['L','R'])\n",
    "m = imp_df.merge(e, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    idx = m['Unnamed: 0'][i]\n",
    "    indices.append(idx)\n",
    "    \n",
    "df_f = e.drop(indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column for contralateral KOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Add other knee column \n",
    "\n",
    "df_f.sort_values(by = 'ID')\n",
    "mask = df_f.duplicated(subset=['ID'], keep = False)\n",
    "\n",
    "# keep only bilateral images \n",
    "df_d = df_f[mask].reset_index()\n",
    "\n",
    "df_d['other_knee_KOA']=''\n",
    "\n",
    "# add other knee fast progressor column\n",
    "for idx, row in df_d.iterrows():\n",
    "\n",
    "    print(idx, end = '\\r')\n",
    "    i = idx+1 # idx = first row, i = following row \n",
    "\n",
    "    if df_d['ID'][i] == df_d['ID'][idx]:\n",
    "        if df_d['KL-grade_a'][idx]>=3:\n",
    "            df_d['other_knee_KOA'][i]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][i]= 0\n",
    "            \n",
    "        if df_d['KL-grade_a'][i]>=3:\n",
    "            df_d['other_knee_KOA'][idx]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][idx]= 0\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_f.merge(df_d[['ID','Laterality','other_knee_KOA']], on = ['ID', 'Laterality'], how = 'left')\n",
    "df_d = df_d.rename(columns = {'img_path':'dicom_img_path'})\n",
    "\n",
    "df_new = df_new.replace({'Patient Sex': {'M': 0}})\n",
    "df_new = df_new.replace({'Patient Sex': {'F': 1}})\n",
    "df_new = df_new.replace({'Hip_symptoms': {'No':0, 'Yes':1, '1: Yes': 1, '.: Missing Form/Incomplete Workbook':np.nan, '8':np.nan, 'P':np.nan}})\n",
    "#df_new = df_new.replace({'Knee_inj': {'1: Yes': 1,'.: Missing Form/Incomplete Workbook':np.nan}})\n",
    "\n",
    "df_new = df_new.replace({'WOMAC_dis': {'M': np.nan}})\n",
    "df_new = df_new.replace({'WOMAC_stiff': {'M': np.nan}})\n",
    "df_new = df_new.replace({'WOMAC_pain': {'M': np.nan}})\n",
    "\n",
    "df_new['WOMAC_dis'] = df_new['WOMAC_dis'].astype('float')\n",
    "df_new['WOMAC_stiff'] = df_new['WOMAC_stiff'].astype('float')\n",
    "df_new['WOMAC_pain'] = df_new['WOMAC_pain'].astype('float')\n",
    "df_new['Hip_symptoms'] = df_new['Hip_symptoms'].astype('float')\n",
    "#df_new['Knee_inj'] = df_new['Knee_inj'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new.copy()\n",
    "\n",
    "# Add cut_img path to dataframe\n",
    "df['img_path_cut']=''\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    l = df.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df['img_path_cut'][i] = fn\n",
    "\n",
    "# Add preprocessed path to dataframe \n",
    "df['img_path_pro']=''\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    l = df.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees/Clahe-pngs', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df['img_path_pro'][i] = fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns={'Unnamed: 0', 'Unnamed: 0.1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')\n",
    "dfs = pd.read_csv('/srv/Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex014.csv')\n",
    "dfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.merge(dfs, on=['ID','Laterality'], how='left')\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns={'Unnamed: 0_x', 'Unnamed: 0_y', 'class_y'})\n",
    "df = df.rename(columns={'class_x':'class'})\n",
    "df.to_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')\n",
    "\n",
    "df2['Patient Sex'] = df['Patient Sex'].astype('float')\n",
    "df2['BMI'] = df['BMI'].astype('float')\n",
    "#df2['Knee_inj'] = df['Knee_inj'].astype('float')\n",
    "df2['Hip_symptoms'] = df['Hip_symptoms'].astype('float')\n",
    "df2['WOMAC_dis'] = df['WOMAC_dis'].astype('float')\n",
    "df2['WOMAC_pain'] = df['WOMAC_pain'].astype('float')\n",
    "df2['KL-grade_a'] = df['KL-grade_a'].astype('float')\n",
    "\n",
    "df3 = df2.dropna()\n",
    "df3 = df3.reset_index()\n",
    "df3.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with OAI, MOST and test with CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOAI = df.loc[df.Study == 'OAI']\n",
    "dfMOST = df.loc[df.Study == 'MOST']\n",
    "dfOAIMOST = df.loc[(df.Study == 'MOST') | (df.Study == 'OAI')]\n",
    "dfCHECK = df.loc[df.Study == 'CHECK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCHECK.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_CHECK.csv')\n",
    "dfOAIMOST.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAIMOST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfOAIMOST.copy()\n",
    "np.random.seed(137115)\n",
    "\n",
    "tune_split = int(len(df) * 0.15)\n",
    "index_tune = np.sort(np.random.choice(range(0, len(df)), size=tune_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_tune)\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAIMOST_train.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAIMOST_tune.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with OAI, CHECK and test with MOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOAICHECK = df.loc[(df.Study == 'CHECK') | (df.Study == 'OAI')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfOAICHECK.copy()\n",
    "np.random.seed(137115)\n",
    "\n",
    "tune_split = int(len(df) * 0.15)\n",
    "index_tune = np.sort(np.random.choice(range(0, len(df)), size=tune_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_tune)\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAICHECK_train.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAICHECK_tune.csv')\n",
    "dfMOST.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_MOST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with CHECK, MOST and test with OAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMOSTCHECK = df.loc[(df.Study == 'CHECK') | (df.Study == 'MOST')]\n",
    "len(dfMOSTCHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfMOSTCHECK.copy()\n",
    "np.random.seed(137115)\n",
    "\n",
    "tune_split = int(len(df) * 0.15)\n",
    "index_tune = np.sort(np.random.choice(range(0, len(df)), size=tune_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_tune)\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_MOSTCHECK_train.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_MOSTCHECK_tune.csv')\n",
    "dfOAI.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_OAI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training, Test, Tune set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "dfTrain.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_train.csv')\n",
    "dfTest.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_test.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/Nonan_Master_20JSN_XML_ex014_2_tune.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masterfile 10% JSN, exclusion of KL0-0, KL1-1, KL4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/JSN_pred_clf_pro.csv')\n",
    "\n",
    "df = df.replace({'Patient Sex': {'M': 0}})\n",
    "df = df.replace({'Patient Sex': {'F': 1}})\n",
    "df = df.replace({'Hip_symptoms': {'No':0, 'Yes':1, '1: Yes': 1, '.: Missing Form/Incomplete Workbook':np.nan, '8':np.nan, 'P':np.nan}})\n",
    "df = df.replace({'Knee_inj': {'1: Yes': 1,'.: Missing Form/Incomplete Workbook':np.nan}})\n",
    "\n",
    "df = df.replace({'WOMAC_dis': {'M': np.nan}})\n",
    "df = df.replace({'WOMAC_stiff': {'M': np.nan}})\n",
    "df = df.replace({'WOMAC_pain': {'M': np.nan}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding columns of KOALA output (sclerosis, osteophytosis, KL)\n",
    "add = pd.read_csv('/srv/XMLExtrKLOsteoScleroAll.csv')\n",
    "df1 = df.merge(add, on = ['Laterality', 'ID'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column for contralateral KOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_f = df1.copy()\n",
    "## Add other knee column \n",
    "\n",
    "df_f.sort_values(by = 'ID')\n",
    "mask = df_f.duplicated(subset=['ID'], keep = False)\n",
    "\n",
    "# keep only bilateral images \n",
    "df_d = df_f[mask].reset_index()\n",
    "\n",
    "df_d['other_knee_KOA']=''\n",
    "\n",
    "# add other knee fast progressor column\n",
    "for idx, row in df_d.iterrows():\n",
    "\n",
    "    print(idx, end = '\\r')\n",
    "    i = idx+1 # idx = first row, i = following row \n",
    "\n",
    "    if df_d['ID'][i] == df_d['ID'][idx]:\n",
    "        if df_d['KL-grade'][idx]>=3:\n",
    "            df_d['other_knee_KOA'][i]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][i]= 0\n",
    "            \n",
    "        if df_d['KL-grade'][i]>=3:\n",
    "            df_d['other_knee_KOA'][idx]= 1\n",
    "        else: \n",
    "            df_d['other_knee_KOA'][idx]= 0\n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_f.merge(df_d[['ID','Laterality','other_knee_KOA']], on = ['ID', 'Laterality'], how = 'left')\n",
    "df_new = df_new.rename(columns = {'img_path':'dicom_img_path'})\n",
    "\n",
    "# make all nan for other_knee_KOA = 0 \n",
    "df_new['other_knee_KOA'] = df_new['other_knee_KOA'].fillna(0)\n",
    "df_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## StandardScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Knee_inj','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade','sclerosis','osteophytes']\n",
    "new_col_names = ['Patient Sex_S','Patient Age_S','BMI_S','Knee_inj_S','Hip_symptoms_S','WOMAC_dis_S','WOMAC_stiff_S','WOMAC_pain_S','other_knee_KOA_S','KL-grade_S','sclerosis_S','osteophytes_S']\n",
    "features = df_new[col_names]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = new_col_names)\n",
    "\n",
    "scaled_features['ID'] = df_new.ID\n",
    "scaled_features['Laterality'] = df_new.Laterality\n",
    "scaled_features['class']= df_new['class']\n",
    "\n",
    "## eliminate all nan values\n",
    "#scaled_features = scaled_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_new.merge(scaled_features, on=['Laterality','ID'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[['Patient ID', 'VISIT', 'Laterality',\n",
    "       'ID', 'Study', 'dicom_img_path', 'Patient Sex', 'Patient Age', 'BMI',\n",
    "       'Knee_inj', 'Hip_symptoms', 'WOMAC_dis', 'WOMAC_pain', 'WOMAC_stiff',\n",
    "       'KL', 'Implant','class_x', 'osteophytes', 'KL-grade', 'sclerosis',\n",
    "       'other_knee_KOA', 'Patient Sex_S', 'Patient Age_S', 'BMI_S','Knee_inj_S',\n",
    "       'Hip_symptoms_S', 'WOMAC_dis_S', 'WOMAC_stiff_S', 'WOMAC_pain_S',\n",
    "       'other_knee_KOA_S', 'KL-grade_S', 'sclerosis_S', 'osteophytes_S']]\n",
    "df2 = df2.rename(columns={'class_x':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MinMaxScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Knee_inj','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade','sclerosis','osteophytes']\n",
    "new_col_names = ['Patient Sex_M','Patient Age_M','BMI_M','Knee_inj_M','Hip_symptoms_M','WOMAC_dis_M','WOMAC_stiff_M','WOMAC_pain_M','other_knee_KOA_M','KL-grade_M','sclerosis_M','osteophytes_M']\n",
    "\n",
    "features = df2[col_names]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = new_col_names)\n",
    "\n",
    "scaled_features['ID'] = df2.ID\n",
    "scaled_features['Laterality'] = df2.Laterality\n",
    "\n",
    "## Eliminiate all nan values\n",
    "#scaled_features = scaled_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.merge(scaled_features, on=['Laterality','ID'], how='left')\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('/srv/Master_10JSN_XML_ex014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Master_10JSN_XML_ex014.csv')\n",
    "df1 = pd.read_csv('/srv/JSN_pred_clf_pro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp= df[['ID','Laterality','Patient Sex_S','Patient Age_S','BMI_S', 'Hip_symptoms_S', 'WOMAC_dis_S', 'WOMAC_pain_S','WOMAC_stiff_S','other_knee_KOA_S','KL-grade_S','class']]\n",
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['Laterality','ID','img_path_pro']]\n",
    "df_new=tmp.merge(df1, on = ['Laterality','ID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('/srv/Master_10JSN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "dfTrain.to_csv('/srv/Master_10JSN_train.csv')\n",
    "dfTest.to_csv('/srv/Master_10JSN_test.csv')\n",
    "dfTune.to_csv('/srv/Master_10JSN_tune.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
