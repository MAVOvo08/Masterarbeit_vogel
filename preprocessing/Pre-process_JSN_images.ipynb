{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess JSN-data\n",
    "Cropping bilateral images into left and right knee (ROI)\n",
    "\n",
    "Preprocess images (resize, normalize, gaussian blur, clahe)\n",
    "\n",
    "Standardize numeric data with Standard Scaler and MinMax normalization\n",
    "\n",
    "\n",
    "\n",
    "author = MV<br>\n",
    "date = 2021-10-19<br>\n",
    "\n",
    "_______________________________________\n",
    "\n",
    "- JSN_pred_clf.csv\n",
    "    - class def: 10% JSN\n",
    "    - exclusion: KL0-0, KL1-1, KL4 at baseline\n",
    "    - with pre-processed img path (img_path)\n",
    "    \n",
    "- JSN_pred_clf_new.csv\n",
    "    - class def: 10% JSN\n",
    "    - exclusion: KL0-0, KL1-1, KL4 at baseline\n",
    "    \n",
    "- JSN_pred_clf_pro.csv\n",
    "    - class def: 10% JSN\n",
    "    - exclusion: KL0-0, KL1-1, KL4 at baseline, implant imgs\n",
    "    - with pre-processed img path (img_path_pro)\n",
    "    \n",
    "- /srv/Class_def_files/JSN_final_pro.csv\n",
    "    - class def: 20% JSN\n",
    "    - exclusion: KL4 at baseline, implant imgs\n",
    "    - with pre-processed img path (img_path_pro)\n",
    "    \n",
    "- /srv/Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex014.csv\n",
    "    - Standard Scaler normalized data of  Master_20JSN_XML_ex014.csv\n",
    "    \n",
    "- /srv/Normalized_numeric_data/MinMax_Master_20JSN_XML_ex014.csv\n",
    "    - MinMax normalized data of  Master_20JSN_XML_ex014.csv\n",
    "    \n",
    "- /srv/Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex4.csv\n",
    "    - Standard Scaler normalized data of  Master_20JSN_XML_ex4.csv\n",
    "    \n",
    "- /srv/Normalized_numeric_data/MinMax_Master_20JSN_XML_ex4.csv\n",
    "    - MinMax normalized data of  Master_20JSN_XML_ex4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this defines the GPU you are using\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for dnn2 and labelbox-connector\n",
    "import sys\n",
    "sys.path.insert(1, \"/srv/dnn-framework2\")\n",
    "\n",
    "sys.path.insert(1, \"/srv/labelbox-connector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import pydicom\n",
    "\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "from framework.data_objects import BoundingBox, PointList2D, DicomImage\n",
    "import ast\n",
    "from framework.inferences import Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from PIL import Image\n",
    "import ast"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# labelbox-connector\n",
    "from LabelBox.LB_project import LBProject\n",
    "from LabelBox.LB_extractor import LBExtractor\n",
    "from LabelBox.LB_parser import LBParser\n",
    "\n",
    "from LabelBox.LB_talker import LBTalker\n",
    "from LabelBox.S3_talker import S3Talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asc' 'time)s %(name)-25s %(level' 'name)-8s %(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO) # you change this to logging.DEBUG to get more logging information"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#session config - if needed\n",
    "import tensorflow.keras.backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop imgs of data with exclusion of KL0-0, KL1-1 and KL4 baseline (10%JSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to crop image ROI if you have the KOALA output for the images\n",
    "\n",
    "def fake_jsw_box(xml_path, side=\"R\"):\n",
    "    xm = etree.parse(xml_path)\n",
    "    region_id = 0 if side==\"R\" else 1\n",
    "    ptlist = []\n",
    "    for loc in {'LAT','MED'}:\n",
    "        #loc = 'LAT' if i==3 else 'MED'\n",
    "        for k in range(4):\n",
    "            xpt = f\"/Analysis/Region[id={region_id}]/MeasurementBoard[id='JSx']/JSx[location='{loc}']/JSW{k}/coordinates\"\n",
    "            if len(xpt) == 0:\n",
    "                continue\n",
    "            xy = ast.literal_eval(xm.xpath(xpt)[0].text.replace(\" \",\",\"))\n",
    "            coords = [ xy[i:i + 2] for i in range(0,len(xy),2)]\n",
    "            ptlist.extend(coords)\n",
    "\n",
    "    ptlist = PointList2D(ptlist)\n",
    "\n",
    "    c = ptlist.center.data\n",
    "    dx = int(1.6 * ptlist.dx)\n",
    "    dy = int(2. * dx)\n",
    "    #print(c, dx, dy)\n",
    "    return BoundingBox.from_center_height_width(c, dy, dx)\n",
    "\n",
    "\n",
    "def cut_img_box(df_in, loc):\n",
    "    l = df_in.loc[loc]['Laterality']\n",
    "    bbox = fake_jsw_box(\"/mnt/temporaer/MV/KOALA_output/xml/\"+df_in.loc[loc]['ID']+\".xml\", l)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop imgs of data with exclusion of only KL4 baseline ( 20% JSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv file with dicom image path\n",
    "\n",
    "df=pd.read_csv('/srv/Class_def_files/JSN_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add dicom path \n",
    "df['dicom_img_path']=''\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end='\\r')  \n",
    "    if df.Study[i] == 'OAI':\n",
    "        df['dicom_img_path'][i] = '/mnt/fs/37_OAI/data/dicom/' +  df['ID'][i] + '.dcm'\n",
    "    elif df.Study[i] == 'MOST':\n",
    "        df['dicom_img_path'][i] = '/mnt/fs/40_MOST/data/dicom/' +  df['ID'][i] + '.dcm'\n",
    "    else:\n",
    "        df['dicom_img_path'][i] = '/mnt/fs/102_CHECK/data/dicom/' +  df['ID'][i] + '.dcm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut img and write in folder\n",
    "\n",
    "compression_params = [cv2.IMWRITE_PNG_COMPRESSION, 0, cv2.IMWRITE_PNG_STRATEGY, cv2.IMWRITE_PNG_STRATEGY_FIXED]\n",
    "maxval = 20000\n",
    "clahe = cv2.createCLAHE(40, (15,15))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    i = i+36820\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "    # cut img\n",
    "    l = df.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    \n",
    "    bbox = fake_jsw_box(\"/mnt/temporaer/MV/KOALA_output/xml/\"+df.loc[i]['ID']+\".xml\", l)\n",
    "    \n",
    "    dicom_path = df.dicom_img_path[i] \n",
    "    dicom_image = DicomImage(dicom_path).load()\n",
    "    img = pydicom.dcmread(dicom_path).pixel_array\n",
    "\n",
    "    cut_image = bbox.cut(img)\n",
    "\n",
    "    # flip if left knee\n",
    "    if l == 'L':\n",
    "        cut_image = np.fliplr(cut_image)\n",
    "\n",
    "    # write image on caroline\n",
    "    cv2.imwrite(fn,cut_image, compression_params)\n",
    "    \n",
    "    # write cropped img path in dataframe \n",
    "    df['img_path'][i]=fn\n",
    "    \n",
    "    ## pre-process img\n",
    "    img_p = cv2.resize(cut_image, (512,1024), interpolation=cv2.INTER_NEAREST)\n",
    "    img_p = cv2.normalize(img_p, img_p,0,maxval,cv2.NORM_MINMAX ,cv2.CV_16UC1)\n",
    "    img_p = cv2.GaussianBlur(img_p,(3,3), 0.3)\n",
    "    img_p = clahe.apply(img_p)\n",
    "\n",
    "    # write pre-processed image on caroline (location you want to store images. Same location of the training notebook)\n",
    "    fn_p = os.path.join('/mnt/caroline/MV/Cropped_knees/Clahe-pngs', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "    cv2.imwrite(fn_p,img_p, compression_params)\n",
    "    \n",
    "    # write image path of the cropped image in dataframe \n",
    "    df['img_path_pro'][i]=fn_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "df.to_csv('/srv/Class_def_files/JSN_final_pro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop residual imgs of Masterfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'img_path':'dicom_img_path'})\n",
    "\n",
    "# cut img and write in folder\n",
    "\n",
    "compression_params = [cv2.IMWRITE_PNG_COMPRESSION, 0, cv2.IMWRITE_PNG_STRATEGY, cv2.IMWRITE_PNG_STRATEGY_FIXED]\n",
    "maxval = 20000\n",
    "clahe = cv2.createCLAHE(40, (15,15))\n",
    "\n",
    "indices=[]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    i = i\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "    try:\n",
    "        test = cv2.imread(df.img_path_pro[i])\n",
    "        plt.imshow(test)\n",
    "    except:\n",
    "        # cut img\n",
    "        l = df.loc[i]['Laterality']\n",
    "        fn = os.path.join('/mnt/caroline/MV/Cropped_knees', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "\n",
    "        bbox = fake_jsw_box(\"/mnt/temporaer/MV/KOALA_output/xml/\"+df.loc[i]['ID']+\".xml\", l)\n",
    "\n",
    "        dicom_path = df.dicom_img_path[i] \n",
    "        dicom_image = DicomImage(dicom_path).load()\n",
    "        img = pydicom.dcmread(dicom_path).pixel_array\n",
    "\n",
    "        cut_image = bbox.cut(img)\n",
    "\n",
    "        # flip if left knee\n",
    "        if l == 'L':\n",
    "            cut_image = np.fliplr(cut_image)\n",
    "\n",
    "        # write image on caroline\n",
    "        cv2.imwrite(fn,cut_image, compression_params)\n",
    "\n",
    "        # write path in dataframe \n",
    "        df['img_path_cut'][i]=fn\n",
    "\n",
    "        ## pre-process img\n",
    "        img_p = cv2.resize(cut_image, (512,1024), interpolation=cv2.INTER_NEAREST)\n",
    "        img_p = cv2.normalize(img_p, img_p,0,maxval,cv2.NORM_MINMAX ,cv2.CV_16UC1)\n",
    "        img_p = cv2.GaussianBlur(img_p,(3,3), 0.3)\n",
    "        img_p = clahe.apply(img_p)\n",
    "\n",
    "        fn_p = os.path.join('/mnt/caroline/MV/Cropped_knees/Clahe-pngs', df.loc[i]['ID']+'_'+ l + '.png')\n",
    "        cv2.imwrite(fn_p,img_p, compression_params)\n",
    "\n",
    "        # write path in dataframe \n",
    "        df['img_path_pro'][i]=fn_p\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training, tune and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting of data 10%JSN\n",
    "\n",
    "df = pd.read_csv('/srv/JSN_pred_clf_pro.csv')\n",
    "\n",
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "\n",
    "dfTrain.to_csv('/srv/JSN_pred_clf_pro_train.csv')\n",
    "dfTest.to_csv('/srv/JSN_pred_clf_pro_test.csv')\n",
    "dfTune.to_csv('/srv/JSN_pred_clf_pro_tune.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting data of data 20% JSN and exclusion of only KL4 baseline\n",
    "\n",
    "#df = pd.read_csv('/srv/Class_def_files/JSN_final_pro.csv')\n",
    "\n",
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "\n",
    "dfTrain.to_csv('/srv/Class_def_files/JSN_final_pro_train.csv')\n",
    "dfTest.to_csv('/srv/Class_def_files/JSN_final_pro_test.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/JSN_final_pro_tune.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort out manually implant images \n",
    "Implants.csv: indices of implant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/srv/JSN_pred_clf_pro.csv')\n",
    "# All bilateral images --> inspection of only right images\n",
    "df_R = df_test.loc[df_test.Laterality=='R']\n",
    "df_new = df_R.reset_index()\n",
    "df2 = df_new[7344:]\n",
    "for i, row in df2.iterrows():\n",
    "    print(i)\n",
    "    plt.imshow(DicomImage(df2.dicom_img_path.loc[i]).load().array,cmap='gray')\n",
    "    print(df2.ID[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminate Implants.csv indices from dataframe (438 images)\n",
    "\n",
    "imp_df = pd.read_csv('/srv/Implants.csv')\n",
    "orig_df = pd.read_csv('/srv/JSN_pred_clf_pro.csv')\n",
    "orig_df = orig_df.drop(columns={'Unnamed: 0.1','Unnamed: 0.1.1','Unnamed: 0.1.1.1', 'Unnamed: 0.1.1.1.1'})\n",
    "orig_df\n",
    "\n",
    "imp_df = imp_df.replace(['l','r'], ['L','R'])\n",
    "m = imp_df.merge(orig_df, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    idx = m['Unnamed: 0'][i]\n",
    "    indices.append(idx)\n",
    "    \n",
    "df_new = orig_df.drop(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('/srv/JSN_pred_clf_pro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize numeric data SKLEARN (StandardScaler & MinMaxScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mastefile with exluscion KL 0,1,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## StandardScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade_a','sclerosis_a','osteophytes_a']\n",
    "new_col_names = ['Patient Sex_S','Patient Age_S','BMI_S','Hip_symptoms_S','WOMAC_dis_S','WOMAC_stiff_S','WOMAC_pain_S','other_knee_KOA_S','KL-grade_a_S','sclerosis_a_S','osteophytes_a_S']\n",
    "features = df[col_names]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = new_col_names)\n",
    "\n",
    "## eliminate all nan values\n",
    "scaled_features = scaled_features.dropna()\n",
    "\n",
    "scaled_features['ID'] = df.ID\n",
    "scaled_features['Laterality'] = df.Laterality\n",
    "scaled_features['class']= df['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features.to_csv('/srv/Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MinMaxScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade_a','sclerosis_a','osteophytes_a']\n",
    "new_col_names = ['Patient Sex_M','Patient Age_M','BMI_M','Hip_symptoms_M','WOMAC_dis_M','WOMAC_stiff_M','WOMAC_pain_M','other_knee_KOA_M','KL-grade_a_M','sclerosis_a_M','osteophytes_a_M']\n",
    "\n",
    "features = df[col_names]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = new_col_names)\n",
    "\n",
    "## Eliminiate all nan values\n",
    "scaled_features = scaled_features.dropna()\n",
    "\n",
    "scaled_features['ID'] = df.ID\n",
    "scaled_features['Laterality'] = df.Laterality\n",
    "scaled_features['class']= df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features.to_csv('/srv/Normalized_numeric_data/MinMax_Master_20JSN_XML_ex014.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masterfile with exclusion KL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## StandardScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade_a','sclerosis_a','osteophytes_a']\n",
    "new_col_names = ['Patient Sex_S','Patient Age_S','BMI_S','Hip_symptoms_S','WOMAC_dis_S','WOMAC_stiff_S','WOMAC_pain_S','other_knee_KOA_S','KL-grade_a_S','sclerosis_a_S','osteophytes_a_S']\n",
    "features = df[col_names]\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = new_col_names)\n",
    "\n",
    "## eliminate all nan values\n",
    "#scaled_features = scaled_features.dropna()\n",
    "scaled_features['ID'] = df.ID\n",
    "scaled_features['Laterality'] = df.Laterality\n",
    "scaled_features['class']= df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features.to_csv('/srv/Normalized_numeric_data/StandardScaler_Master_20JSN_XML_ex4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MinMaxScaler\n",
    "col_names = ['Patient Sex','Patient Age','BMI','Knee_inj','Hip_symptoms','WOMAC_dis','WOMAC_stiff','WOMAC_pain','other_knee_KOA','KL-grade_a','sclerosis_a','osteophytes_a']\n",
    "features = df[col_names]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = col_names)\n",
    "\n",
    "## Eliminiate all nan values\n",
    "scaled_features = scaled_features.dropna()\n",
    "\n",
    "scaled_features['class']= df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features.to_csv('/srv/Normalized_numeric_data/MinMax_Master_20JSN_XML_ex4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Parameter tuning for Pre-processing of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_img_box(df_in, loc):\n",
    "    l = df_in.loc[loc]['Laterality']\n",
    "    bbox = fake_jsw_box(\"/mnt/temporaer/MV/KOALA_output/xml/\"+df_in.loc[loc]['ID']+\".xml\", l)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/JSN_pred_clf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output:\n",
    "# 1. normalized, hist-equalized, 16 bit img\n",
    "# 2. stats of histograms mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather info:\n",
    "# 1. mix/max ranges in all images\n",
    "# 2. good range for the 16bit pixel value range [0, 2^N -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = []\n",
    "maxes = []\n",
    "windows = []\n",
    "means = []\n",
    "stds = []\n",
    "global_hist = np.zeros((2**16 - 1),dtype=np.int64)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    dcm = DicomImage(row['dicom_img_path']).load().array\n",
    "    min_i = dcm.min()\n",
    "    max_i = dcm.max()\n",
    "    windows.append(max_i-min_i)\n",
    "    maxes.append(max_i)\n",
    "    mins.append(min_i)\n",
    "    means.append(dcm.mean())\n",
    "    stds.append(dcm.std())\n",
    "    global_hist = np.histogram(dcm, (2**16 - 1))[0] + global_hist\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale(\"log\")\n",
    "plt.plot(global_hist,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MIN\"] = mins\n",
    "df['MAX'] = maxes\n",
    "df['window'] = windows\n",
    "df['means'] = means\n",
    "df['stds'] = stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((means<30000)&(means>10000))\n",
    "list1 = indices.tolist()\n",
    "\n",
    "for idx in list1:\n",
    "    df.drop(idx, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices2 = np.argwhere((means>60000))\n",
    "list2 = indices2.tolist()\n",
    "\n",
    "for idx in list2:\n",
    "    df.drop(idx, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add columns of Min, Max, widnow, means, stds to csv file\n",
    "df.to_csv('/srv/JSN_pred_clf_pro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.window, 'r*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array(means)\n",
    "\n",
    "maxval = 20000\n",
    "clahe = cv2.createCLAHE(40, (20,20))\n",
    "\n",
    "me = int(np.random.uniform()*df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm = DicomImage(df.dicom_img_path.loc[100]).load()\n",
    "\n",
    "img = None\n",
    "img = cut_img_box(df, 100).cut(dcm.array)\n",
    "\n",
    "img = cv2.resize(img, (512,1024), interpolation=cv2.INTER_NEAREST)\n",
    "img = cv2.normalize(img, img,0,maxval,cv2.NORM_MINMAX,cv2.CV_16UC1)\n",
    "#img = cv2.GaussianBlur(img,(3,3), 0.3)\n",
    "img = cv2.equalizeHist(img)\n",
    "#img = clahe.apply(img)\n",
    "\n",
    "plt.figure(figsize=(8,13))\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
