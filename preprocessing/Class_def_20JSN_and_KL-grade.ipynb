{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class definition with 20% JSN and with KL-grade\n",
    "Code to extract to calculate progressing KOA classes with 20% JSN and KL-grade\n",
    "\n",
    "\n",
    "author = MV<br>\n",
    "date = 2021-10-04<br>\n",
    "\n",
    "_______________________________________\n",
    "\n",
    "- /srv/Class_def_files/JSN_final.csv    \n",
    "    - class def: 20% JSN\n",
    "    - exclusion of only KL 4 at baseline\n",
    "    \n",
    "- /srv/Class_def_files/KL_def_final.csv\n",
    "    - class def: from KL 0, 1 to 3, 4 in <= 4 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this defines the GPU you are using\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths for dnn2 and labelbox-connector\n",
    "import sys\n",
    "sys.path.insert(1, \"/srv/dnn-framework2\")\n",
    "sys.path.insert(1, \"/srv/labelbox-connector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import pydicom\n",
    "\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "from framework.data_objects import BoundingBox, PointList2D, DicomImage\n",
    "import ast\n",
    "from framework.inferences import Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asc' 'time)s %(name)-25s %(level' 'name)-8s %(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO) # you change this to logging.DEBUG to get more logging information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition with 20% JSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate JSN/year and Classify into slow and fast progressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSW_all.csv content:\n",
    "#   All images a and images b with 1 and 2 year interval \n",
    "\n",
    "df6 = pd.read_csv('/srv/Class_def_files/JSW_all_2.csv')\n",
    "\n",
    "for i, row in df6.iterrows(): \n",
    "    print(i)\n",
    "    \n",
    "    # calculate difference btw. JSW of image a and image b \n",
    "    diff_MED = float(df6.JSW_MIN_MED_a[i]) - float(df6.JSW_MIN_MED_b[i]) \n",
    "    diff_LAT = float(df6.JSW_MIN_LAT_a[i]) - float(df6.JSW_MIN_LAT_b[i])\n",
    "    \n",
    "    ## MED\n",
    "    if 0 > diff_MED > -0.4: # tolerance of -0.4mm == difference is 0 \n",
    "        diff_MED = 0 \n",
    "    else:\n",
    "        s=1\n",
    "    \n",
    "    if (diff_MED >= 0) & (float(df6.JSW_MIN_MED_a[i]) > 0): \n",
    "        reduction_MED = diff_MED/float(df6.JSW_MIN_MED_a[i]) # calculate percentage of baseline \n",
    "\n",
    "        if (reduction_MED < 0.2)| (diff_MED < 0.4) :\n",
    "            df6.class_MED[i] = 0 # less than 20% --> slow progr. (class 0)\n",
    "        else:\n",
    "            df6.class_MED[i] = 1 # else --> fast progr. (class 1)\n",
    "    else:\n",
    "        df6.class_MED[i] = np.nan\n",
    "        \n",
    "    ## LAT\n",
    "    if 0 > diff_LAT > -0.4:\n",
    "        diff_LAT = 0 \n",
    "    else:\n",
    "        s=1\n",
    "        \n",
    "    if (diff_LAT >= 0) & (float(df6.JSW_MIN_LAT_a[i]) > 0):\n",
    "        reduction_LAT = diff_LAT/float(df6.JSW_MIN_LAT_a[i])\n",
    "\n",
    "        if (reduction_LAT < 0.2)| (diff_LAT < 0.4):\n",
    "            df6.class_LAT[i] = 0\n",
    "        else:\n",
    "            df6.class_LAT[i] = 1\n",
    "    else:\n",
    "        df6.class_LAT[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('/srv/Class_def_files/JSW_all_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusion criteria KL 4 (raw KL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/JSW_all_2.csv')\n",
    "df_x = df.dropna(subset=['class_MED','class_LAT'], how = 'all')\n",
    "print(len(df_x))\n",
    "\n",
    "\n",
    "# if KL stays 1\n",
    "#df_z = df_x.drop(df_x[(df_x['KL_a'] ==1) & (df_x['KL_b'] ==1)].index)\n",
    "#print(len(df_z))\n",
    "\n",
    "# id KL_a is 4\n",
    "df8 = df_x[df_x.KL_a != 4]\n",
    "\n",
    "df8['KL_a'] = df8['KL_a'].replace([1.9,5,8,9],np.nan)\n",
    "df8['KL_b'] = df8['KL_b'].replace([1.9,5,8,9],np.nan)\n",
    "\n",
    "# add one general class combining class_MED and class_LAT\n",
    "df8['class']=''\n",
    "for i, row in df8.iterrows():\n",
    "    if (df8['class_MED'][i]==1) | (df['class_LAT'][i]==1):\n",
    "        df8['class'][i]=1\n",
    "    else:\n",
    "        df8['class'][i]=0\n",
    "        \n",
    "print('Length of Dataset with applied exclusion criteria:',len(df8))\n",
    "print('Number of right knees:', len(df8[df8.Laterality == 'R']))\n",
    "print('Number of left knees:', len(df8[df8.Laterality == 'L']))\n",
    "\n",
    "print(\"Number of medial slow progressors:\",len(df8.loc[df8.class_MED == 0]))\n",
    "print(\"Number of medial fast progressors:\",len(df8.loc[df8.class_MED == 1]))\n",
    "\n",
    "print(\"Number of lateral slow progressors:\",len(df8.loc[df8.class_LAT == 0]))\n",
    "print(\"Number of lateral fast progressors:\",len(df8.loc[df8.class_LAT == 1]))\n",
    "\n",
    "print('Class 0:',len(df8.loc[df8['class'] == 0]))\n",
    "print('Class 1:',len(df8.loc[df8['class'] == 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains Image a and Image b with class_MED and class_LAT and general class \n",
    "# Exclusion criteria are applied\n",
    "df8.to_csv('/srv/Class_def_files/JSW_excluded_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class to master csv\n",
    "df_master = pd.read_csv('/srv/Master_dataset_JSN.csv')\n",
    "\n",
    "df7_tmp = df8.rename(columns = {'ID_a':'ID'})\n",
    "df_c = df_master.merge(df7_tmp[['ID','Laterality','coords_bbox_a','class_MED','class_LAT','class']], on = ['ID','Laterality'], how = 'right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_csv('/srv/Class_def_files/JSN_pred_clf_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE IMG PATH OF OAI\n",
    "\n",
    "df = pd.read_csv('/srv/Class_def_files/JSN_pred_clf_2.csv')\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(i, end = '\\r')\n",
    "    if df.Study[i] =='OAI':\n",
    "        IDnum = df['ID'][i]\n",
    "        IDnum = str(IDnum)\n",
    "        fn = \"/mnt/fs/37_OAI/data/dicom/\" + IDnum + \".dcm\"\n",
    "\n",
    "        df['img_path'][i] = fn\n",
    "        \n",
    "\n",
    "df.to_csv('/srv/Class_def_files/JSN_pred_clf_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate bad segmented images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('/srv/Class_def_files/JSN_pred_clf_2.csv')\n",
    "a = pd.read_csv('/srv/Class_def_files/FailedKOALAxml.csv')\n",
    "\n",
    "a = a.replace(['l','r'], ['L','R']).rename(columns={'Side': 'Laterality'})\n",
    "m = a.merge(c, on = ['Laterality', 'ID'], how = 'inner')\n",
    "\n",
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    index = m['Unnamed: 0'][i]\n",
    "    indices.append(index)\n",
    "    \n",
    "\n",
    "d = c.drop(indices, axis = 0).reset_index()\n",
    "e = d.drop(columns=['index','Unnamed: 0'])\n",
    "\n",
    "e.to_csv('/srv/Class_def_files/JSN_pred_clf_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column of contralateral knee OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/Master_20JSN_XML_ex014.csv')\n",
    "df['other_knee_AKOA']=''\n",
    "print(len(df))\n",
    "df.sort_values(by = 'ID')\n",
    "mask = df.duplicated(subset=['ID'], keep = False)\n",
    "\n",
    "# keep only bilateral images \n",
    "df_d = df[mask].reset_index()\n",
    "df_d\n",
    "print(len(df_d))\n",
    "\n",
    "# add other knee fast progressor column\n",
    "for idx, row in df_d.iterrows():\n",
    "\n",
    "    print(idx, end = '\\r')\n",
    "    i = idx+1 # idx = first row, i = following row \n",
    "\n",
    "    if df_d['ID'][i] == df_d['ID'][idx]:\n",
    "        if df_d['class'][idx]==1:\n",
    "            df_d['other_knee_AKOA'][i]= 1\n",
    "        else: \n",
    "            df_d['other_knee_AKOA'][i]= 0\n",
    "            \n",
    "        if df_d['class'][i]==1:\n",
    "            df_d['other_knee_AKOA'][idx]= 1\n",
    "        else: \n",
    "            df_d['other_knee_AKOA'][idx]= 0\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "df_d = df_d.rename(columns = {'img_path':'dicom_img_path'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.merge(df_d[['ID','Laterality','other_knee_AKOA']], on = ['ID', 'Laterality'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new2 = df_new.drop(columns = {'Unnamed: 0','Unnamed: 0.1','other_knee_AKOA_x'})\n",
    "df_new2 = df_new2.rename(columns = {'other_knee_AKOA_y':'other_knee_AKOA'})\n",
    "df_new2\n",
    "\n",
    "## Add image path to Caroline \n",
    "df_new2['img_path'] = ''\n",
    "df_new2['img_path_pro'] = ''\n",
    "for i, row in df_new2.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    l = df_new2.loc[i]['Laterality']\n",
    "    fn = os.path.join('/mnt/caroline/MV/Cropped_knees', df_new2.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df_new2['img_path'][i]=fn\n",
    "    \n",
    "    fn2 = os.path.join('/mnt/caroline/MV/Cropped_knees/Clahe-pngs', df_new2.loc[i]['ID']+'_'+ l + '.png')\n",
    "    df_new2['img_path_pro'][i]=fn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new2.to_csv('/srv/Class_def_files/JSN_tmp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate Implants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Eliminate from dataframe (438 images)\n",
    "\n",
    "imp_df = pd.read_csv('/srv/Implants.csv')\n",
    "orig_df = pd.read_csv('/srv/Class_def_files/JSN_tmp.csv')\n",
    "\n",
    "imp_df = imp_df.replace(['l','r'], ['L','R'])\n",
    "m = imp_df.merge(orig_df, on = ['Laterality', 'ID'], how = 'inner')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i, row in m.iterrows():\n",
    "    idx = m['Unnamed: 0'][i]\n",
    "    indices.append(idx)\n",
    "    \n",
    "df_new3 = orig_df.drop(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new3.to_csv('/srv/Class_def_files/JSN_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training Test Tune set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/srv/Class_def_files/JSN_final.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(137115)\n",
    "train_split = int(len(df) * 0.8)\n",
    "test_split = len(df) - train_split\n",
    "\n",
    "index_test = np.sort(np.random.choice(range(0, len(df)), size=test_split, replace=False))\n",
    "index_train = np.delete(range(0, len(df)), index_test)\n",
    "\n",
    "tune_split = int(len(index_train) * 0.15)\n",
    "bla = np.sort(np.random.choice(range(0, len(index_train)), size=tune_split, replace=False))\n",
    "bla2 = np.delete(range(0, len(index_train)), bla)\n",
    "index_tune = index_train[bla]\n",
    "index_train = index_train[bla2]\n",
    "\n",
    "dfTrain = df.iloc[index_train]\n",
    "dfTune = df.iloc[index_tune]\n",
    "dfTest = df.iloc[index_test]\n",
    "\n",
    "dfTrain.to_csv('/srv/Class_def_files/JSN_final_train.csv')\n",
    "dfTest.to_csv('/srv/Class_def_files/JSN_final_test.csv')\n",
    "dfTune.to_csv('/srv/Class_def_files/JSN_final_tune.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition with KL grade taken from KOaLA (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/srv/Class_def_files/JSW_all_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter images with at least 4 year interval\n",
    "\n",
    "# load master file\n",
    "df_master = pd.read_csv('/srv/Master_dataset_JSN.csv')\n",
    "df_tmp = df_master.copy()\n",
    "df_tmp['tmp'] =''\n",
    "\n",
    "# Change visit from V00 to 0 (number to calculate)\n",
    "df_tmp[['VISIT']] = df_tmp[['VISIT']].replace(\n",
    "    ['V00','V01','V02','V03','V04','V05','V06','V07','V08','V09','V10'],\n",
    "    [0,1,2,3,4,5,6,7,8,9,10])\n",
    "df_tmp = df_tmp.astype({'Patient ID': 'str'})\n",
    "\n",
    "# split into left and right dataframe dfL & dfR\n",
    "dfL = df_tmp.loc[df_tmp['Laterality']=='L'].reset_index()\n",
    "dfR = df_tmp.loc[df_tmp['Laterality']=='R'].reset_index()\n",
    "\n",
    "\n",
    "# Dataframe with 'a' as year 0 and 'b' as year 1 or 2\n",
    "df_img_L = pd.DataFrame(columns={'Study','Patient ID','Image_a','Image_b','ID_a','ID_b','VISIT_a','VISIT_b', 'KL_a','KL_b'})\n",
    "\n",
    "# left knees\n",
    "for idx, row in dfL.iterrows():\n",
    "    print(idx, end='\\r')\n",
    "    if idx < 40027:\n",
    "        i = idx+1 # to have to following rows i and idx \n",
    "        if dfL['Patient ID'][i] == dfL['Patient ID'][idx]: # make sure its same Patient \n",
    "            if (dfL['VISIT'][i] - dfL['VISIT'][idx])<= 4: # Visit with 4 year interval \n",
    "                \n",
    "                row = {\n",
    "                    'ID_a': dfL['ID'][idx],\n",
    "                    'ID_b': dfL['ID'][i],\n",
    "                    'Image_a': dfL['img_path'][idx],\n",
    "                    'Image_b': dfL['img_path'][i],\n",
    "                    'VISIT_a': dfL['VISIT'][idx],\n",
    "                    'VISIT_b': dfL['VISIT'][i],\n",
    "                    'KL_a' : dfL['KL'][idx],\n",
    "                    'KL_b' : dfL['KL'][i],\n",
    "                    'Patient ID': dfL['Patient ID'][idx],\n",
    "                    'Study' : dfL['Study'][idx]\n",
    "                }\n",
    "                df_img_L = df_img_L.append(row, ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "        else: \n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "        \n",
    "df_img_R = pd.DataFrame(columns={'Study','Patient ID','Image_a','Image_b','ID_a','ID_b','VISIT_a','VISIT_b', 'KL_a','KL_b'})\n",
    "\n",
    "# right side \n",
    "for idx, row in dfR.iterrows():\n",
    "    print(idx, end='\\r')\n",
    "    if idx < 40021:\n",
    "        i = idx+1\n",
    "        if dfR['Patient ID'][i] == dfR['Patient ID'][idx]:\n",
    "            if (dfR['VISIT'][i] - dfR['VISIT'][idx])<= 4:\n",
    "                \n",
    "                row = {\n",
    "                    'ID_a': dfR['ID'][idx],\n",
    "                    'ID_b': dfR['ID'][i],\n",
    "                    'Image_a': dfR['img_path'][idx],\n",
    "                    'Image_b': dfR['img_path'][i],\n",
    "                    'VISIT_a': dfR['VISIT'][idx],\n",
    "                    'VISIT_b': dfR['VISIT'][i],\n",
    "                    'KL_a' : dfR['KL'][idx],\n",
    "                    'KL_b' : dfR['KL'][i],\n",
    "                    'Patient ID': dfR['Patient ID'][idx],\n",
    "                    'Study' : dfR['Study'][idx]\n",
    "                    \n",
    "                }\n",
    "                df_img_R = df_img_R.append(row, ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "        else: \n",
    "            continue\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "df_img_L['Laterality']='L'\n",
    "df_img_R['Laterality']='R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.concat([df_img_L,df_img_R], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns of ostephytosis and sclerosis\n",
    "df_bla = pd.read_csv('/srv/XMLExtrKLOsteoScleroAll.csv')\n",
    "df_bla.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write KL grade of imageA\n",
    "tmp = df_bla.rename(columns={'ID':'ID_a','KL-grade':'KL-grade_a', 'osteophytes':'osteophytes_a','sclerosis':'sclerosis_a'})\n",
    "df1 = df_m.merge(tmp, on=['ID_a','Laterality'], how='left')\n",
    "\n",
    "# write KL grade of imageB\n",
    "tmp = df_bla.rename(columns={'ID':'ID_b','KL-grade':'KL-grade_b', 'osteophytes':'osteophytes_b','sclerosis':'sclerosis_b'})\n",
    "df2 = df1.merge(tmp, on=['ID_b','Laterality'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns={'Unnamed: 0_x','Unnamed: 0_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('/srv/temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate KL difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/srv/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3['class']=''\n",
    "for i, row in df3.iterrows():\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "    if (df3['KL-grade_a'][i] < 2) & (df3['KL-grade_b'][i] > 2):\n",
    "        df3['class'][i]=1\n",
    "    else:\n",
    "        df3['class'][i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(df3.loc[df3['KL-grade_a']==-1].index, inplace =True)\n",
    "df3.drop(df3.loc[df3['KL-grade_b']==-1].index, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class to master csv\n",
    "df_master = pd.read_csv('/srv/Master_dataset_JSN.csv')\n",
    "\n",
    "df_tmp = df3.rename(columns = {'ID_a':'ID'})\n",
    "df_c = df_master.merge(df_tmp, on = ['ID','Laterality'], how = 'right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_csv('/srv/Class_def_files/KL_def_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
